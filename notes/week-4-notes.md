# Week-4
These notes prepared during week-4 of ML Zoomcamp. 

# 1 Evaluation metrics: session overview
- Churn prediction - model to predict customers leaving the company - accuracy = 80%
- What does't the accuracy metric mean? 
- Are there other metrics to evaluate our binary classificaiton model? 
- `Metric` is a function that compares the predictions with the actual values and outputs in a single number that tells how good the predictions are

- Accuracy and Dummy models 
- Other metrics 
    - Confusion table 
    - Precision and Recall 
    - ROC curve
    - ROC-AUC 
    - K-fold Cross Validation 

# 2 Accuracy and dummy model

# 3 Confusion table

# 4 Precision and Recall

# 5 ROC Curves

# 6 ROC AUC

# 7 Cross-Validation

# 8 Summary

# 9 Explore more

# 10 Homework
